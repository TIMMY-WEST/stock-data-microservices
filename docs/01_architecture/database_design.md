# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­è¨ˆæ›¸ (MVPç‰ˆ)

## 1. è¨­è¨ˆæ¦‚è¦

### 1.1 è¨­è¨ˆæ–¹é‡
- **ã‚·ãƒ³ãƒ—ãƒ«ãƒ•ã‚¡ãƒ¼ã‚¹ãƒˆ**: MVP ã«å¿…è¦æœ€å°é™ã®ãƒ†ãƒ¼ãƒ–ãƒ«æ§‹æˆ
- **æ­£è¦åŒ–**: åŸºæœ¬çš„ãªæ­£è¦åŒ–ï¼ˆç¬¬3æ­£è¦å½¢ã¾ã§ï¼‰
- **æ‹¡å¼µæ€§**: å°†æ¥ã®æ©Ÿèƒ½è¿½åŠ ã«å¯¾å¿œå¯èƒ½ãªè¨­è¨ˆ
- **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹**: åŸºæœ¬çš„ãªã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è¨­å®š

### 1.2 ä½¿ç”¨æŠ€è¡“
- **RDBMS**: PostgreSQL 15+
- **ORM**: SQLAlchemy 2.0+
- **Migration**: Alembic
- **é–‹ç™ºç’°å¢ƒ**: Docker Compose (PostgreSQL ã‚³ãƒ³ãƒ†ãƒŠ)

## 2. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹æˆ

### 2.1 ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æƒ…å ±
```yaml
ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å: stock_data_db
æ–‡å­—ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°: UTF-8
ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³: Asia/Tokyo
æ¥ç¶šãƒãƒ¼ãƒˆ: 5432
```

### 2.2 ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§

| ãƒ†ãƒ¼ãƒ–ãƒ«å | ç”¨é€” | å„ªå…ˆåº¦ |
|-----------|------|--------|
| stock_data | æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ï¼ˆæ—¥è¶³ï¼‰ | ğŸ”´ MVPå¿…é ˆ |
| fetch_logs | ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ­ã‚° | ğŸ”´ MVPå¿…é ˆ |
| stock_symbols | éŠ˜æŸ„ãƒã‚¹ã‚¿ | ğŸŸ¡ æ‹¡å¼µæ™‚ |

## 3. ãƒ†ãƒ¼ãƒ–ãƒ«è¨­è¨ˆè©³ç´°

### 3.1 stock_data ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆæ ªä¾¡ãƒ‡ãƒ¼ã‚¿ï¼‰

**ç”¨é€”**: Yahoo Finance ã‹ã‚‰å–å¾—ã—ãŸæ—¥è¶³æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã‚’æ ¼ç´

```sql
CREATE TABLE stock_data (
    id SERIAL PRIMARY KEY,
    symbol VARCHAR(20) NOT NULL,                    -- éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ (ä¾‹: 7203.T)
    date DATE NOT NULL,                            -- å–å¼•æ—¥
    open DECIMAL(10, 2),                           -- å§‹å€¤
    high DECIMAL(10, 2),                           -- é«˜å€¤  
    low DECIMAL(10, 2),                            -- å®‰å€¤
    close DECIMAL(10, 2) NOT NULL,                 -- çµ‚å€¤
    adj_close DECIMAL(10, 2),                      -- èª¿æ•´å¾Œçµ‚å€¤
    volume BIGINT,                                 -- å‡ºæ¥é«˜
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP, -- ä½œæˆæ—¥æ™‚
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP, -- æ›´æ–°æ—¥æ™‚
    
    -- åˆ¶ç´„
    CONSTRAINT uk_stock_data_symbol_date UNIQUE (symbol, date)
);

-- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
CREATE INDEX idx_stock_data_symbol ON stock_data (symbol);
CREATE INDEX idx_stock_data_date ON stock_data (date);
CREATE INDEX idx_stock_data_symbol_date ON stock_data (symbol, date);
```

#### ã‚«ãƒ©ãƒ è©³ç´°

| ã‚«ãƒ©ãƒ å | ãƒ‡ãƒ¼ã‚¿å‹ | NULL | èª¬æ˜ | ä¾‹ |
|---------|---------|------|------|---|
| id | SERIAL | NOT NULL | ä¸»ã‚­ãƒ¼ï¼ˆè‡ªå‹•æ¡ç•ªï¼‰ | 1, 2, 3... |
| symbol | VARCHAR(20) | NOT NULL | éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ | "7203.T", "6758.T" |
| date | DATE | NOT NULL | å–å¼•æ—¥ | "2024-01-15" |
| open | DECIMAL(10,2) | NULL | å§‹å€¤ | 2500.50 |
| high | DECIMAL(10,2) | NULL | é«˜å€¤ | 2580.00 |
| low | DECIMAL(10,2) | NULL | å®‰å€¤ | 2480.25 |
| close | DECIMAL(10,2) | NOT NULL | çµ‚å€¤ | 2530.75 |
| adj_close | DECIMAL(10,2) | NULL | èª¿æ•´å¾Œçµ‚å€¤ | 2530.75 |
| volume | BIGINT | NULL | å‡ºæ¥é«˜ | 1500000 |
| created_at | TIMESTAMP | NOT NULL | ä½œæˆæ—¥æ™‚ | "2024-01-15 10:30:00" |
| updated_at | TIMESTAMP | NOT NULL | æ›´æ–°æ—¥æ™‚ | "2024-01-15 10:30:00" |

### 3.2 fetch_logs ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆå–å¾—ãƒ­ã‚°ï¼‰

**ç”¨é€”**: ãƒ‡ãƒ¼ã‚¿å–å¾—å‡¦ç†ã®å®Ÿè¡Œå±¥æ­´ãƒ»çµæœã‚’è¨˜éŒ²

```sql
CREATE TABLE fetch_logs (
    id SERIAL PRIMARY KEY,
    fetch_id UUID NOT NULL,                        -- å–å¾—å‡¦ç†IDï¼ˆãƒãƒƒãƒè­˜åˆ¥ç”¨ï¼‰
    symbol VARCHAR(20),                            -- å¯¾è±¡éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰
    status VARCHAR(20) NOT NULL,                   -- å‡¦ç†çµæœ ('success', 'error', 'skipped')
    start_date DATE,                               -- å–å¾—é–‹å§‹æ—¥
    end_date DATE,                                 -- å–å¾—çµ‚äº†æ—¥  
    records_count INTEGER DEFAULT 0,              -- å–å¾—ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°
    error_message TEXT,                           -- ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    processing_time_ms INTEGER,                   -- å‡¦ç†æ™‚é–“ï¼ˆãƒŸãƒªç§’ï¼‰
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP -- å®Ÿè¡Œæ—¥æ™‚
);

-- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
CREATE INDEX idx_fetch_logs_fetch_id ON fetch_logs (fetch_id);
CREATE INDEX idx_fetch_logs_symbol ON fetch_logs (symbol);  
CREATE INDEX idx_fetch_logs_status ON fetch_logs (status);
CREATE INDEX idx_fetch_logs_created_at ON fetch_logs (created_at);
```

#### ã‚«ãƒ©ãƒ è©³ç´°

| ã‚«ãƒ©ãƒ å | ãƒ‡ãƒ¼ã‚¿å‹ | NULL | èª¬æ˜ | ä¾‹ |
|---------|---------|------|------|---|
| id | SERIAL | NOT NULL | ä¸»ã‚­ãƒ¼ | 1, 2, 3... |
| fetch_id | UUID | NOT NULL | ãƒãƒƒãƒå‡¦ç†ID | "550e8400-e29b-41d4-a716-446655440000" |
| symbol | VARCHAR(20) | NULL | éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ | "7203.T" |
| status | VARCHAR(20) | NOT NULL | å‡¦ç†çµæœ | "success", "error", "skipped" |
| start_date | DATE | NULL | å–å¾—æœŸé–“é–‹å§‹æ—¥ | "2023-01-15" |
| end_date | DATE | NULL | å–å¾—æœŸé–“çµ‚äº†æ—¥ | "2024-01-15" |
| records_count | INTEGER | NOT NULL | å–å¾—ä»¶æ•° | 252 |
| error_message | TEXT | NULL | ã‚¨ãƒ©ãƒ¼å†…å®¹ | "Invalid symbol" |
| processing_time_ms | INTEGER | NULL | å‡¦ç†æ™‚é–“ | 1500 |
| created_at | TIMESTAMP | NOT NULL | å®Ÿè¡Œæ™‚åˆ» | "2024-01-15 10:30:00" |

## 4. SQLAlchemy ãƒ¢ãƒ‡ãƒ«å®šç¾©

### 4.1 models/stock_data.py

```python
from datetime import datetime, date
from decimal import Decimal
from sqlalchemy import Column, Integer, String, Date, DateTime, Numeric, BigInteger, Text
from sqlalchemy.ext.declarative import declarative_base

Base = declarative_base()

class StockData(Base):
    """æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«"""
    __tablename__ = 'stock_data'
    
    id = Column(Integer, primary_key=True)
    symbol = Column(String(20), nullable=False, index=True)
    date = Column(Date, nullable=False, index=True)
    open = Column(Numeric(10, 2))
    high = Column(Numeric(10, 2))
    low = Column(Numeric(10, 2))
    close = Column(Numeric(10, 2), nullable=False)
    adj_close = Column(Numeric(10, 2))
    volume = Column(BigInteger)
    created_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
    
    # ãƒ¦ãƒ‹ãƒ¼ã‚¯åˆ¶ç´„
    __table_args__ = (
        {'schema': None}
    )
    
    def __repr__(self):
        return f"<StockData(symbol='{self.symbol}', date='{self.date}', close={self.close})>"
    
    def to_dict(self):
        """è¾æ›¸å½¢å¼ã§ã®å‡ºåŠ›"""
        return {
            'id': self.id,
            'symbol': self.symbol,
            'date': self.date.isoformat() if self.date else None,
            'open': float(self.open) if self.open else None,
            'high': float(self.high) if self.high else None,
            'low': float(self.low) if self.low else None,
            'close': float(self.close) if self.close else None,
            'adj_close': float(self.adj_close) if self.adj_close else None,
            'volume': self.volume,
            'created_at': self.created_at.isoformat() if self.created_at else None,
            'updated_at': self.updated_at.isoformat() if self.updated_at else None
        }

class FetchLog(Base):
    """å–å¾—ãƒ­ã‚°ãƒ¢ãƒ‡ãƒ«"""
    __tablename__ = 'fetch_logs'
    
    id = Column(Integer, primary_key=True)
    fetch_id = Column(String(36), nullable=False, index=True)  # UUID string
    symbol = Column(String(20), index=True)
    status = Column(String(20), nullable=False, index=True)
    start_date = Column(Date)
    end_date = Column(Date)
    records_count = Column(Integer, default=0)
    error_message = Column(Text)
    processing_time_ms = Column(Integer)
    created_at = Column(DateTime, default=datetime.utcnow, index=True)
    
    def __repr__(self):
        return f"<FetchLog(fetch_id='{self.fetch_id}', symbol='{self.symbol}', status='{self.status}')>"
    
    def to_dict(self):
        return {
            'id': self.id,
            'fetch_id': self.fetch_id,
            'symbol': self.symbol,
            'status': self.status,
            'start_date': self.start_date.isoformat() if self.start_date else None,
            'end_date': self.end_date.isoformat() if self.end_date else None,
            'records_count': self.records_count,
            'error_message': self.error_message,
            'processing_time_ms': self.processing_time_ms,
            'created_at': self.created_at.isoformat() if self.created_at else None
        }
```

## 5. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ“ä½œ

### 5.1 åŸºæœ¬çš„ãªCRUDæ“ä½œ

#### æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜
```python
def save_stock_data(symbol: str, data: list, mode: str = 'overwrite'):
    """
    æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
    
    Args:
        symbol: éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰
        data: æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ãƒªã‚¹ãƒˆ
        mode: 'overwrite' | 'skip'
    """
    session = Session()
    try:
        for record in data:
            if mode == 'skip':
                # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Œã°ã‚¹ã‚­ãƒƒãƒ—
                existing = session.query(StockData).filter(
                    StockData.symbol == symbol,
                    StockData.date == record['date']
                ).first()
                if existing:
                    continue
            
            # ãƒ‡ãƒ¼ã‚¿ä¿å­˜ï¼ˆä¸Šæ›¸ããƒ¢ãƒ¼ãƒ‰ï¼‰
            stock_data = StockData(
                symbol=symbol,
                date=record['date'],
                open=record['open'],
                high=record['high'],
                low=record['low'],
                close=record['close'],
                adj_close=record.get('adj_close'),
                volume=record.get('volume')
            )
            session.merge(stock_data)  # INSERT ã¾ãŸã¯ UPDATE
            
        session.commit()
        
    except Exception as e:
        session.rollback()
        raise e
    finally:
        session.close()
```

#### æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã®å–å¾—
```python
def get_stock_data(symbol: str = None, start_date: date = None, end_date: date = None, 
                  page: int = 1, per_page: int = 100):
    """
    æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    
    Args:
        symbol: éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ï¼ˆæŒ‡å®šæ™‚ã¯è©²å½“éŠ˜æŸ„ã®ã¿ï¼‰
        start_date: é–‹å§‹æ—¥
        end_date: çµ‚äº†æ—¥
        page: ãƒšãƒ¼ã‚¸ç•ªå·
        per_page: 1ãƒšãƒ¼ã‚¸ã‚ãŸã‚Šã®ä»¶æ•°
    
    Returns:
        dict: {'data': [...], 'total': ä»¶æ•°, 'page': ãƒšãƒ¼ã‚¸, 'per_page': ä»¶æ•°}
    """
    session = Session()
    
    query = session.query(StockData)
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
    if symbol:
        query = query.filter(StockData.symbol == symbol)
    if start_date:
        query = query.filter(StockData.date >= start_date)
    if end_date:
        query = query.filter(StockData.date <= end_date)
    
    # ä¸¦ã³é †
    query = query.order_by(StockData.symbol, StockData.date.desc())
    
    # ç·ä»¶æ•°
    total = query.count()
    
    # ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³
    offset = (page - 1) * per_page
    data = query.offset(offset).limit(per_page).all()
    
    session.close()
    
    return {
        'data': [item.to_dict() for item in data],
        'total': total,
        'page': page,
        'per_page': per_page,
        'pages': (total + per_page - 1) // per_page
    }
```

### 5.2 ãƒ­ã‚°è¨˜éŒ²

```python
def log_fetch_result(fetch_id: str, symbol: str, status: str, 
                    records_count: int = 0, error_message: str = None,
                    processing_time_ms: int = None):
    """å–å¾—çµæœã‚’ãƒ­ã‚°ã«è¨˜éŒ²"""
    session = Session()
    try:
        log = FetchLog(
            fetch_id=fetch_id,
            symbol=symbol,
            status=status,
            records_count=records_count,
            error_message=error_message,
            processing_time_ms=processing_time_ms
        )
        session.add(log)
        session.commit()
    finally:
        session.close()
```

## 6. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

### 6.1 Docker Composeè¨­å®š

```yaml
# docker-compose.yml
version: '3.8'

services:
  postgres:
    image: postgres:15
    container_name: stock_postgres
    environment:
      POSTGRES_DB: stock_data_db
      POSTGRES_USER: stock_user
      POSTGRES_PASSWORD: stock_password
      TZ: Asia/Tokyo
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql
    restart: unless-stopped

volumes:
  postgres_data:
```

### 6.2 åˆæœŸåŒ–SQL

```sql
-- init.sql
-- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä½œæˆå¾Œã®åˆæœŸè¨­å®š

-- ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³è¨­å®š
SET timezone = 'Asia/Tokyo';

-- æ‹¡å¼µæ©Ÿèƒ½æœ‰åŠ¹åŒ–
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";

-- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆï¼ˆãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆå¾Œï¼‰
-- stock_data ãƒ†ãƒ¼ãƒ–ãƒ«ç”¨
CREATE INDEX IF NOT EXISTS idx_stock_data_symbol ON stock_data (symbol);
CREATE INDEX IF NOT EXISTS idx_stock_data_date ON stock_data (date);
CREATE INDEX IF NOT EXISTS idx_stock_data_symbol_date ON stock_data (symbol, date);

-- fetch_logs ãƒ†ãƒ¼ãƒ–ãƒ«ç”¨
CREATE INDEX IF NOT EXISTS idx_fetch_logs_fetch_id ON fetch_logs (fetch_id);
CREATE INDEX IF NOT EXISTS idx_fetch_logs_symbol ON fetch_logs (symbol);
CREATE INDEX IF NOT EXISTS idx_fetch_logs_status ON fetch_logs (status);
CREATE INDEX IF NOT EXISTS idx_fetch_logs_created_at ON fetch_logs (created_at);
```

### 6.3 Alembic Migrationè¨­å®š

```python
# alembic/env.py
import os
from alembic import context
from sqlalchemy import engine_from_config, pool
from app.models.stock_data import Base

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šURL
DATABASE_URL = os.getenv('DATABASE_URL', 'postgresql://stock_user:stock_password@localhost:5432/stock_data_db')

config = context.config
config.set_main_option('sqlalchemy.url', DATABASE_URL)

target_metadata = Base.metadata

def run_migrations_online():
    connectable = engine_from_config(
        config.get_section(config.config_ini_section),
        prefix='sqlalchemy.',
        poolclass=pool.NullPool,
    )

    with connectable.connect() as connection:
        context.configure(
            connection=connection, target_metadata=target_metadata
        )

        with context.begin_transaction():
            context.run_migrations()

run_migrations_online()
```

## 7. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è€ƒæ…®äº‹é …

### 7.1 ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æˆ¦ç•¥

**å¿…é ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹:**
- `stock_data(symbol)` - éŠ˜æŸ„åˆ¥æ¤œç´¢ç”¨
- `stock_data(date)` - æ—¥ä»˜ç¯„å›²æ¤œç´¢ç”¨  
- `stock_data(symbol, date)` - è¤‡åˆæ¤œç´¢ç”¨

**å°†æ¥è¿½åŠ äºˆå®š:**
- `stock_data(symbol, date DESC)` - æœ€æ–°ãƒ‡ãƒ¼ã‚¿å–å¾—ç”¨
- ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ‹ãƒ³ã‚°ï¼ˆå¹´åˆ¥ï¼‰

### 7.2 ã‚¯ã‚¨ãƒªæœ€é©åŒ–

```sql
-- è‰¯ã„ã‚¯ã‚¨ãƒªä¾‹ï¼šã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ´»ç”¨
SELECT * FROM stock_data 
WHERE symbol = '7203.T' 
  AND date >= '2024-01-01' 
ORDER BY date DESC 
LIMIT 100;

-- é¿ã‘ã‚‹ã¹ãã‚¯ã‚¨ãƒªï¼šãƒ•ãƒ«ã‚¹ã‚­ãƒ£ãƒ³ç™ºç”Ÿ
SELECT * FROM stock_data 
WHERE EXTRACT(YEAR FROM date) = 2024;  -- é–¢æ•°ä½¿ç”¨ã§ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç„¡åŠ¹åŒ–
```

## 8. ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ»å¾©æ—§

### 8.1 ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

```bash
#!/bin/bash
# backup.sh - ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—

DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_DIR="/backup"
DB_NAME="stock_data_db"

# ãƒ•ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
docker exec stock_postgres pg_dump -U stock_user $DB_NAME > $BACKUP_DIR/stock_db_$DATE.sql

# åœ§ç¸®
gzip $BACKUP_DIR/stock_db_$DATE.sql

echo "Backup completed: stock_db_$DATE.sql.gz"
```

### 8.2 å¾©æ—§æ‰‹é †

```bash
# 1. ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã®å¾©å…ƒ
gunzip stock_db_20240115_100000.sql.gz

# 2. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å¾©æ—§
docker exec -i stock_postgres psql -U stock_user -d stock_data_db < stock_db_20240115_100000.sql
```

## ã¾ã¨ã‚

ã“ã®MVPç‰ˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­è¨ˆã§ã¯ï¼š

### âœ… **å®Ÿè£…ç¯„å›²**
- æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ä¿å­˜ï¼ˆstock_dataï¼‰
- å–å¾—ãƒ­ã‚°ç®¡ç†ï¼ˆfetch_logsï¼‰
- åŸºæœ¬çš„ãªCRUDæ“ä½œ
- Docker ã§ã®ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒæ§‹ç¯‰

### ğŸš€ **æ‹¡å¼µæº–å‚™**
- éŠ˜æŸ„ãƒã‚¹ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆå°†æ¥è¿½åŠ ï¼‰
- ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ‹ãƒ³ã‚°å¯¾å¿œ
- ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³æº–å‚™
- ç›£è¦–ãƒ»ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†

ã“ã®è¨­è¨ˆã«ã‚ˆã‚Šã€ã‚·ãƒ³ãƒ—ãƒ«ã§å®Ÿç”¨çš„ãªãƒ‡ãƒ¼ã‚¿ç®¡ç†ãŒå¯èƒ½ã§ã™ã€‚