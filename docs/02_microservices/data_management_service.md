# Data Management Service ä»•æ§˜æ›¸

## 1. ã‚µãƒ¼ãƒ“ã‚¹æ¦‚è¦

### 1.1 å½¹å‰²
- PostgreSQLãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã§ã®ãƒ‡ãƒ¼ã‚¿æ“ä½œ
- æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã®æ°¸ç¶šåŒ–ãƒ»æ¤œç´¢ãƒ»å‰Šé™¤
- ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ã®ä¿è¨¼
- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®æœ€é©åŒ–

### 1.2 æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯
- **Framework**: FastAPI (å°†æ¥) / Flaskå†…ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« (MVP)
- **Port**: 8002 (å°†æ¥) / internal (MVP)
- **Dependencies**: SQLAlchemy, psycopg2-binary, alembic
- **Database**: PostgreSQL
- **Current Implementation**: `services/database.py` + `models/`

## 2. å†…éƒ¨APIä»•æ§˜ï¼ˆãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹æ™‚ï¼‰

### 2.1 ãƒ‡ãƒ¼ã‚¿ä¿å­˜

#### POST /internal/save-stock-data
æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜

**ãƒªã‚¯ã‚¨ã‚¹ãƒˆ:**
```http
POST /internal/save-stock-data HTTP/1.1
Content-Type: application/json

{
  "symbol": "7203.T",
  "mode": "overwrite",
  "data": [
    {
      "symbol": "7203.T",
      "date": "2024-01-15",
      "open": 2520.00,
      "high": 2580.50,
      "low": 2510.25,
      "close": 2530.75,
      "adj_close": 2530.75,
      "volume": 1250000
    }
  ]
}
```

**ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**
| ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | å‹ | å¿…é ˆ | èª¬æ˜ | ä¾‹ |
|-----------|---|------|------|---|
| symbol | string | âœ… | éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ | "7203.T" |
| mode | string | âœ… | ä¿å­˜ãƒ¢ãƒ¼ãƒ‰ | "overwrite", "skip", "append" |
| data | array | âœ… | æ ªä¾¡ãƒ‡ãƒ¼ã‚¿é…åˆ— | StockData[] |

**ãƒ¬ã‚¹ãƒãƒ³ã‚¹:**
```json
{
  "status": "success",
  "symbol": "7203.T",
  "records_processed": 252,
  "records_saved": 252,
  "records_skipped": 0,
  "records_updated": 0,
  "processing_time_ms": 1500,
  "date_range": {
    "start": "2023-01-15",
    "end": "2024-01-15"
  }
}
```

### 2.2 ãƒ‡ãƒ¼ã‚¿å–å¾—

#### GET /internal/stocks
æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ä¸€è¦§ã®å–å¾—

**ãƒªã‚¯ã‚¨ã‚¹ãƒˆ:**
```http
GET /internal/stocks?page=1&limit=50&symbol=7203.T&start_date=2024-01-01 HTTP/1.1
```

**ã‚¯ã‚¨ãƒªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**
| ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | å‹ | å¿…é ˆ | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ | èª¬æ˜ |
|-----------|---|------|-----------|------|
| page | integer | âŒ | 1 | ãƒšãƒ¼ã‚¸ç•ªå· |
| limit | integer | âŒ | 50 | 1ãƒšãƒ¼ã‚¸ã‚ãŸã‚Šã®ä»¶æ•° |
| symbol | string | âŒ | - | éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ |
| start_date | string | âŒ | - | é–‹å§‹æ—¥ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ |
| end_date | string | âŒ | - | çµ‚äº†æ—¥ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ |

**ãƒ¬ã‚¹ãƒãƒ³ã‚¹:**
```json
{
  "stocks": [
    {
      "symbol": "7203.T",
      "company_name": "ãƒˆãƒ¨ã‚¿è‡ªå‹•è»Š",
      "data_count": 252,
      "date_range": {
        "start": "2023-01-15",
        "end": "2024-01-15"
      },
      "latest_close": 2530.75,
      "latest_date": "2024-01-15",
      "created_at": "2024-01-15T10:30:45+09:00",
      "updated_at": "2024-01-15T10:30:45+09:00"
    }
  ],
  "pagination": {
    "page": 1,
    "limit": 50,
    "total": 1,
    "pages": 1,
    "has_next": false,
    "has_prev": false
  }
}
```

#### GET /internal/stocks/{symbol}/data
ç‰¹å®šéŠ˜æŸ„ã®è©³ç´°ãƒ‡ãƒ¼ã‚¿å–å¾—

**ãƒªã‚¯ã‚¨ã‚¹ãƒˆ:**
```http
GET /internal/stocks/7203.T/data?start_date=2024-01-01&end_date=2024-01-31 HTTP/1.1
```

**ãƒ¬ã‚¹ãƒãƒ³ã‚¹:**
```json
{
  "symbol": "7203.T",
  "company_name": "ãƒˆãƒ¨ã‚¿è‡ªå‹•è»Š",
  "price_data": [
    {
      "date": "2024-01-31",
      "open": 2520.00,
      "high": 2580.50,
      "low": 2510.25,
      "close": 2530.75,
      "adj_close": 2530.75,
      "volume": 1250000
    }
  ],
  "summary": {
    "period": {
      "start": "2024-01-01",
      "end": "2024-01-31"
    },
    "total_records": 22,
    "price_range": {
      "high": 2580.50,
      "low": 2485.00
    }
  }
}
```

### 2.3 ãƒ‡ãƒ¼ã‚¿å‰Šé™¤

#### DELETE /internal/stocks/{symbol}
ç‰¹å®šéŠ˜æŸ„ã®ãƒ‡ãƒ¼ã‚¿å‰Šé™¤

**ãƒªã‚¯ã‚¨ã‚¹ãƒˆ:**
```http
DELETE /internal/stocks/7203.T HTTP/1.1
```

**ãƒ¬ã‚¹ãƒãƒ³ã‚¹:**
```json
{
  "status": "success",
  "symbol": "7203.T",
  "deleted_records": 252,
  "operation_time_ms": 150
}
```

### 2.4 ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯

#### GET /internal/health
ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šçŠ¶æ³ç¢ºèª

**ãƒ¬ã‚¹ãƒãƒ³ã‚¹:**
```json
{
  "status": "healthy",
  "version": "1.0.0",
  "database": {
    "status": "connected",
    "response_time_ms": 15,
    "connection_pool": {
      "active": 2,
      "idle": 8,
      "total": 10
    }
  },
  "metrics": {
    "total_symbols": 45,
    "total_records": 11340,
    "disk_usage_mb": 125
  }
}
```

## 3. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­è¨ˆ

### 3.1 ãƒ†ãƒ¼ãƒ–ãƒ«å®šç¾©

```sql
-- æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«
CREATE TABLE stock_data (
    id SERIAL PRIMARY KEY,
    symbol VARCHAR(10) NOT NULL,
    date DATE NOT NULL,
    open DECIMAL(10,2),
    high DECIMAL(10,2),
    low DECIMAL(10,2),
    close DECIMAL(10,2),
    adj_close DECIMAL(10,2),
    volume BIGINT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    -- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ»åˆ¶ç´„
    UNIQUE(symbol, date),
    INDEX idx_symbol_date (symbol, date),
    INDEX idx_date (date),
    INDEX idx_symbol (symbol)
);

-- éŠ˜æŸ„ãƒã‚¹ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«
CREATE TABLE stock_symbols (
    symbol VARCHAR(10) PRIMARY KEY,
    company_name VARCHAR(255),
    market VARCHAR(50),
    sector VARCHAR(100),
    industry VARCHAR(100),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    INDEX idx_company_name (company_name)
);

-- å–å¾—ãƒ­ã‚°ãƒ†ãƒ¼ãƒ–ãƒ«  
CREATE TABLE fetch_logs (
    id SERIAL PRIMARY KEY,
    fetch_id UUID NOT NULL,
    symbol VARCHAR(10),
    status VARCHAR(20) CHECK (status IN ('success', 'error', 'skipped')),
    error_message TEXT,
    records_count INTEGER,
    processing_time_ms INTEGER,
    fetch_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    INDEX idx_fetch_id (fetch_id),
    INDEX idx_symbol_status (symbol, status),
    INDEX idx_fetch_date (fetch_date)
);
```

### 3.2 SQLAlchemy ãƒ¢ãƒ‡ãƒ«å®šç¾©

```python
# models/stock.py - ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«å®šç¾©
from sqlalchemy import Column, Integer, String, Date, DECIMAL, BigInteger, DateTime, Text, CheckConstraint
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.sql import func
from datetime import datetime
from typing import Optional

Base = declarative_base()

class StockData(Base):
    __tablename__ = 'stock_data'
    
    id = Column(Integer, primary_key=True)
    symbol = Column(String(10), nullable=False, index=True)
    date = Column(Date, nullable=False, index=True)
    open = Column(DECIMAL(10, 2))
    high = Column(DECIMAL(10, 2))
    low = Column(DECIMAL(10, 2))
    close = Column(DECIMAL(10, 2))
    adj_close = Column(DECIMAL(10, 2))
    volume = Column(BigInteger)
    created_at = Column(DateTime, default=func.now())
    updated_at = Column(DateTime, default=func.now(), onupdate=func.now())
    
    __table_args__ = (
        UniqueConstraint('symbol', 'date', name='unique_symbol_date'),
        Index('idx_symbol_date', 'symbol', 'date'),
    )
    
    def to_dict(self) -> dict:
        """è¾æ›¸å½¢å¼ã«å¤‰æ›"""
        return {
            'id': self.id,
            'symbol': self.symbol,
            'date': self.date.isoformat() if self.date else None,
            'open': float(self.open) if self.open else None,
            'high': float(self.high) if self.high else None,
            'low': float(self.low) if self.low else None,
            'close': float(self.close) if self.close else None,
            'adj_close': float(self.adj_close) if self.adj_close else None,
            'volume': self.volume,
            'created_at': self.created_at.isoformat() if self.created_at else None,
            'updated_at': self.updated_at.isoformat() if self.updated_at else None
        }

class StockSymbol(Base):
    __tablename__ = 'stock_symbols'
    
    symbol = Column(String(10), primary_key=True)
    company_name = Column(String(255), index=True)
    market = Column(String(50))
    sector = Column(String(100))
    industry = Column(String(100))
    created_at = Column(DateTime, default=func.now())
    updated_at = Column(DateTime, default=func.now(), onupdate=func.now())

class FetchLog(Base):
    __tablename__ = 'fetch_logs'
    
    id = Column(Integer, primary_key=True)
    fetch_id = Column(String(36), nullable=False, index=True)  # UUID
    symbol = Column(String(10), index=True)
    status = Column(String(20), CheckConstraint("status IN ('success', 'error', 'skipped')"))
    error_message = Column(Text)
    records_count = Column(Integer)
    processing_time_ms = Column(Integer)
    fetch_date = Column(DateTime, default=func.now(), index=True)
```

## 4. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ“ä½œå®Ÿè£…

### 4.1 ãƒ‡ãƒ¼ã‚¿ä¿å­˜ã‚µãƒ¼ãƒ“ã‚¹

```python
# services/database.py - ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ“ä½œå®Ÿè£…
from sqlalchemy.orm import sessionmaker
from sqlalchemy import create_engine, func
from models.stock import Base, StockData, StockSymbol, FetchLog
from typing import List, Dict, Optional, Tuple
import logging
from datetime import datetime, date

class DatabaseService:
    def __init__(self, database_url: str):
        self.engine = create_engine(database_url, pool_size=10, max_overflow=20)
        self.SessionLocal = sessionmaker(bind=self.engine)
        self.logger = logging.getLogger(__name__)
        
        # ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
        Base.metadata.create_all(bind=self.engine)
    
    async def save_stock_data(
        self, 
        symbol: str, 
        data: List[Dict], 
        mode: str = "overwrite"
    ) -> Dict:
        """
        æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜
        
        Args:
            symbol: éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰
            data: æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ
            mode: ä¿å­˜ãƒ¢ãƒ¼ãƒ‰ ("overwrite", "skip", "append")
            
        Returns:
            ä¿å­˜çµæœ
        """
        start_time = datetime.now()
        
        with self.SessionLocal() as session:
            try:
                # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†
                if mode == "overwrite":
                    deleted_count = session.query(StockData).filter(
                        StockData.symbol == symbol
                    ).delete()
                    self.logger.info(f"Deleted {deleted_count} existing records for {symbol}")
                
                saved_count = 0
                skipped_count = 0
                updated_count = 0
                
                for record in data:
                    existing_record = None
                    
                    if mode != "overwrite":
                        existing_record = session.query(StockData).filter(
                            StockData.symbol == symbol,
                            StockData.date == record["date"]
                        ).first()
                    
                    if existing_record:
                        if mode == "skip":
                            skipped_count += 1
                            continue
                        elif mode == "append":
                            # æ—¢å­˜ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’æ›´æ–°
                            for key, value in record.items():
                                if key != "symbol" and key != "date" and value is not None:
                                    setattr(existing_record, key, value)
                            existing_record.updated_at = datetime.now()
                            updated_count += 1
                    else:
                        # æ–°è¦ãƒ¬ã‚³ãƒ¼ãƒ‰ä½œæˆ
                        stock_data = StockData(
                            symbol=record["symbol"],
                            date=datetime.strptime(record["date"], "%Y-%m-%d").date(),
                            open=record.get("open"),
                            high=record.get("high"),
                            low=record.get("low"),
                            close=record.get("close"),
                            adj_close=record.get("adj_close"),
                            volume=record.get("volume")
                        )
                        session.add(stock_data)
                        saved_count += 1
                
                session.commit()
                
                processing_time = (datetime.now() - start_time).total_seconds() * 1000
                
                # æ—¥ä»˜ç¯„å›²ã®è¨ˆç®—
                date_range = self._get_date_range(session, symbol)
                
                return {
                    "status": "success",
                    "symbol": symbol,
                    "records_processed": len(data),
                    "records_saved": saved_count,
                    "records_skipped": skipped_count,
                    "records_updated": updated_count,
                    "processing_time_ms": int(processing_time),
                    "date_range": date_range
                }
                
            except Exception as e:
                session.rollback()
                self.logger.error(f"Error saving data for {symbol}: {str(e)}")
                raise
    
    async def get_stocks_list(
        self,
        page: int = 1,
        limit: int = 50,
        symbol: Optional[str] = None,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None
    ) -> Dict:
        """æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ä¸€è¦§ã®å–å¾—"""
        
        with self.SessionLocal() as session:
            # ãƒ™ãƒ¼ã‚¹ã‚¯ã‚¨ãƒª
            query = session.query(StockData.symbol, func.count().label('data_count'))
            
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶
            if symbol:
                query = query.filter(StockData.symbol.ilike(f"%{symbol}%"))
            
            if start_date:
                query = query.filter(StockData.date >= start_date)
            
            if end_date:
                query = query.filter(StockData.date <= end_date)
            
            # ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã¨ãƒšãƒ¼ã‚¸ãƒ³ã‚°
            query = query.group_by(StockData.symbol)
            total = query.count()
            
            offset = (page - 1) * limit
            results = query.offset(offset).limit(limit).all()
            
            # è©³ç´°æƒ…å ±ã®å–å¾—
            stocks = []
            for result in results:
                stock_info = self._get_stock_summary(session, result.symbol)
                stock_info["data_count"] = result.data_count
                stocks.append(stock_info)
            
            return {
                "stocks": stocks,
                "pagination": {
                    "page": page,
                    "limit": limit,
                    "total": total,
                    "pages": (total + limit - 1) // limit,
                    "has_next": page * limit < total,
                    "has_prev": page > 1
                }
            }
    
    async def get_stock_data(
        self,
        symbol: str,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
        page: int = 1,
        limit: int = 100
    ) -> Dict:
        """ç‰¹å®šéŠ˜æŸ„ã®è©³ç´°ãƒ‡ãƒ¼ã‚¿å–å¾—"""
        
        with self.SessionLocal() as session:
            # ãƒ™ãƒ¼ã‚¹ã‚¯ã‚¨ãƒª
            query = session.query(StockData).filter(StockData.symbol == symbol)
            
            # æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
            if start_date:
                query = query.filter(StockData.date >= start_date)
            if end_date:
                query = query.filter(StockData.date <= end_date)
            
            # ä¸¦ã³é †
            query = query.order_by(StockData.date.desc())
            
            # ãƒšãƒ¼ã‚¸ãƒ³ã‚°
            total = query.count()
            offset = (page - 1) * limit
            records = query.offset(offset).limit(limit).all()
            
            if not records:
                raise ValueError(f"No data found for symbol {symbol}")
            
            # çµ±è¨ˆæƒ…å ±ã®è¨ˆç®—
            summary_query = session.query(
                func.min(StockData.date).label('start'),
                func.max(StockData.date).label('end'),
                func.count().label('total_records'),
                func.max(StockData.high).label('highest'),
                func.min(StockData.low).label('lowest')
            ).filter(StockData.symbol == symbol)
            
            if start_date:
                summary_query = summary_query.filter(StockData.date >= start_date)
            if end_date:
                summary_query = summary_query.filter(StockData.date <= end_date)
            
            summary = summary_query.first()
            
            return {
                "symbol": symbol,
                "company_name": self._get_company_name(session, symbol),
                "price_data": [record.to_dict() for record in records],
                "summary": {
                    "period": {
                        "start": summary.start.isoformat() if summary.start else None,
                        "end": summary.end.isoformat() if summary.end else None
                    },
                    "total_records": summary.total_records,
                    "price_range": {
                        "high": float(summary.highest) if summary.highest else None,
                        "low": float(summary.lowest) if summary.lowest else None
                    }
                },
                "pagination": {
                    "page": page,
                    "limit": limit,
                    "total": total,
                    "pages": (total + limit - 1) // limit,
                    "has_next": page * limit < total,
                    "has_prev": page > 1
                }
            }
    
    async def delete_stock_data(self, symbol: str) -> Dict:
        """ç‰¹å®šéŠ˜æŸ„ã®ãƒ‡ãƒ¼ã‚¿å‰Šé™¤"""
        start_time = datetime.now()
        
        with self.SessionLocal() as session:
            try:
                deleted_count = session.query(StockData).filter(
                    StockData.symbol == symbol
                ).delete()
                
                session.commit()
                
                processing_time = (datetime.now() - start_time).total_seconds() * 1000
                
                return {
                    "status": "success",
                    "symbol": symbol,
                    "deleted_records": deleted_count,
                    "operation_time_ms": int(processing_time)
                }
                
            except Exception as e:
                session.rollback()
                self.logger.error(f"Error deleting data for {symbol}: {str(e)}")
                raise
    
    def _get_stock_summary(self, session, symbol: str) -> Dict:
        """éŠ˜æŸ„ã‚µãƒãƒªãƒ¼æƒ…å ±ã®å–å¾—"""
        
        # æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã®å–å¾—
        latest = session.query(StockData).filter(
            StockData.symbol == symbol
        ).order_by(StockData.date.desc()).first()
        
        # æ—¥ä»˜ç¯„å›²ã®å–å¾—
        date_range = self._get_date_range(session, symbol)
        
        # ä¼šç¤¾åã®å–å¾—
        company_name = self._get_company_name(session, symbol)
        
        return {
            "symbol": symbol,
            "company_name": company_name,
            "date_range": date_range,
            "latest_close": float(latest.close) if latest and latest.close else None,
            "latest_date": latest.date.isoformat() if latest else None,
            "created_at": latest.created_at.isoformat() if latest else None,
            "updated_at": latest.updated_at.isoformat() if latest else None
        }
    
    def _get_date_range(self, session, symbol: str) -> Dict:
        """æ—¥ä»˜ç¯„å›²ã®å–å¾—"""
        result = session.query(
            func.min(StockData.date).label('start'),
            func.max(StockData.date).label('end')
        ).filter(StockData.symbol == symbol).first()
        
        return {
            "start": result.start.isoformat() if result.start else None,
            "end": result.end.isoformat() if result.end else None
        }
    
    def _get_company_name(self, session, symbol: str) -> Optional[str]:
        """ä¼šç¤¾åã®å–å¾—"""
        stock_symbol = session.query(StockSymbol).filter(
            StockSymbol.symbol == symbol
        ).first()
        
        return stock_symbol.company_name if stock_symbol else None
```

## 5. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

### 5.1 ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æˆ¦ç•¥

```sql
-- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„ã®ãŸã‚ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
CREATE INDEX CONCURRENTLY idx_stock_data_symbol_date_desc ON stock_data (symbol, date DESC);
CREATE INDEX CONCURRENTLY idx_stock_data_date_range ON stock_data (date) WHERE date >= '2020-01-01';
CREATE INDEX CONCURRENTLY idx_fetch_logs_symbol_status_date ON fetch_logs (symbol, status, fetch_date);

-- ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³åŒ–ï¼ˆå¤§é‡ãƒ‡ãƒ¼ã‚¿å¯¾å¿œï¼‰
CREATE TABLE stock_data_2024 PARTITION OF stock_data 
FOR VALUES FROM ('2024-01-01') TO ('2025-01-01');
```

### 5.2 ã‚¯ã‚¨ãƒªæœ€é©åŒ–

```python
# services/database.py - ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–
class DatabaseService:
    
    async def bulk_insert_stock_data(self, data: List[Dict]) -> Dict:
        """ãƒãƒ«ã‚¯ã‚¤ãƒ³ã‚µãƒ¼ãƒˆã«ã‚ˆã‚‹é«˜é€Ÿãƒ‡ãƒ¼ã‚¿æŒ¿å…¥"""
        
        with self.SessionLocal() as session:
            try:
                # ãƒãƒ«ã‚¯ã‚¤ãƒ³ã‚µãƒ¼ãƒˆç”¨ã®ãƒ‡ãƒ¼ã‚¿æº–å‚™
                bulk_data = []
                for record in data:
                    bulk_data.append({
                        'symbol': record['symbol'],
                        'date': datetime.strptime(record['date'], "%Y-%m-%d").date(),
                        'open': record.get('open'),
                        'high': record.get('high'),
                        'low': record.get('low'),
                        'close': record.get('close'),
                        'adj_close': record.get('adj_close'),
                        'volume': record.get('volume'),
                        'created_at': datetime.now(),
                        'updated_at': datetime.now()
                    })
                
                # ãƒãƒ«ã‚¯ã‚¤ãƒ³ã‚µãƒ¼ãƒˆå®Ÿè¡Œ
                session.bulk_insert_mappings(StockData, bulk_data)
                session.commit()
                
                return {"status": "success", "records_inserted": len(bulk_data)}
                
            except Exception as e:
                session.rollback()
                raise
    
    async def get_stock_data_cached(self, symbol: str, **kwargs) -> Dict:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½ä»˜ããƒ‡ãƒ¼ã‚¿å–å¾—"""
        
        cache_key = f"stock_data:{symbol}:{hash(frozenset(kwargs.items()))}"
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å–å¾—ã‚’è©¦è¡Œï¼ˆRedisä½¿ç”¨æ™‚ï¼‰
        # cached_result = await self.redis_client.get(cache_key)
        # if cached_result:
        #     return json.loads(cached_result)
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å–å¾—
        result = await self.get_stock_data(symbol, **kwargs)
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜ï¼ˆ5åˆ†é–“ï¼‰
        # await self.redis_client.setex(cache_key, 300, json.dumps(result))
        
        return result
```

## 6. ç¾åœ¨ã®MVPå®Ÿè£…

### 6.1 MVPæ™‚ã®ãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ 
```
services/
â””â”€â”€ database.py         # ç¾åœ¨ã®å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«
models/
â””â”€â”€ stock.py           # SQLAlchemy ãƒ¢ãƒ‡ãƒ«
```

### 6.2 ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹ç§»è¡Œæº–å‚™

```python
# services/database.py - ç§»è¡Œæº–å‚™ã®å®Ÿè£…
from abc import ABC, abstractmethod

class DataManagementServiceInterface(ABC):
    """Data Management Service ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹"""
    
    @abstractmethod
    async def save_stock_data(self, symbol: str, data: List[Dict], mode: str) -> Dict:
        pass
    
    @abstractmethod
    async def get_stocks_list(self, **kwargs) -> Dict:
        pass
    
    @abstractmethod
    async def health_check(self) -> Dict:
        pass

class DatabaseService(DataManagementServiceInterface):
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ“ä½œå®Ÿè£…ï¼ˆMVPæ™‚ã®å†…éƒ¨å®Ÿè£…ï¼‰"""
    
    async def handle_request(self, endpoint: str, method: str, data: dict):
        """çµ±ä¸€ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒãƒ³ãƒ‰ãƒ©ï¼ˆå°†æ¥ã®HTTP APIç”¨ï¼‰"""
        
        if endpoint == '/internal/save-stock-data' and method == 'POST':
            return await self.save_stock_data(
                data['symbol'], data['data'], data['mode']
            )
        
        elif endpoint == '/internal/stocks' and method == 'GET':
            return await self.get_stocks_list(**data)
        
        elif endpoint.startswith('/internal/stocks/') and method == 'GET':
            symbol = endpoint.split('/')[-2]  # Extract symbol from path
            return await self.get_stock_data(symbol, **data)
        
        elif endpoint.startswith('/internal/stocks/') and method == 'DELETE':
            symbol = endpoint.split('/')[-1]
            return await self.delete_stock_data(symbol)
        
        elif endpoint == '/internal/health' and method == 'GET':
            return await self.health_check()
        
        else:
            raise ValueError(f"Unknown endpoint: {endpoint}")
```

---

## ã¾ã¨ã‚

ã“ã®Data Management Serviceä»•æ§˜æ›¸ã§ã¯ï¼š

### âœ… **ç¾åœ¨ã®MVPå¯¾å¿œ**
- `services/database.py` + `models/` ã§ã®å®Ÿè£…
- SQLAlchemy ã«ã‚ˆã‚‹ ORM
- PostgreSQL ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ“ä½œ

### ğŸš€ **å°†æ¥ã®ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹å¯¾å¿œ**
- FastAPI ã«ã‚ˆã‚‹ç‹¬ç«‹ã‚µãƒ¼ãƒ“ã‚¹åŒ–æº–å‚™
- çµ±ä¸€ã•ã‚ŒãŸAPIè¨­è¨ˆ
- ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

### ğŸ›¡ï¸ **ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒ»ä¿¡é ¼æ€§**
- ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³å‡¦ç†
- ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆ¶ç´„ã®æ´»ç”¨

ã“ã®è¨­è¨ˆã«ã‚ˆã‚Šã€å®‰å…¨ã§é«˜ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãªãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚’å®Ÿç¾ã—ã€å°†æ¥ã®æ‹¡å¼µã«å¯¾å¿œã§ãã¾ã™ã€‚